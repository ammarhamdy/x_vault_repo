
**==Large Language Models (LLMs) are AI algorithms that can process user inputs and create [plausible](https://translate.google.com/?sl=en&tl=ar&text=plausible&op=translate) responses by predicting sequences of words==**. 

They are trained on huge semi-public data sets, using machine learning to analyze how the component parts of language fit together.

LLMs usually present a chat interface to accept user input, known as a prompt. 

The input allowed is controlled in part by input validation rules.

LLMs can have a wide range of use cases in modern websites:
- Customer service, such as a virtual assistant.
- Translation.
- SEO improvement.
- Analysis of user-generated content, for example to track the tone of on-page comments.

---

A **large language model (LLM)** is a type of artificial intelligence designed to understand, generate, and process human language. 

These models are trained on vast amounts of text data and use deep learning techniques—especially transformer architectures like **GPT (Generative Pre-trained Transformer)**—to predict and generate text based on input.

---
# LLM attacks and prompt injection

Many web LLM attacks rely on a technique known as prompt injection. 

This is where an attacker uses crafted prompts to manipulate an LLM's output. 

Prompt injection can result in the AI taking actions that fall outside of its intended purpose, such as making incorrect calls to sensitive APIs or returning content that does not correspond to its guidelines.


----
# Detecting LLM vulnerabilities

Our recommended methodology for detecting LLM vulnerabilities is:

1. Identify the LLM's inputs, including both direct (such as a prompt) and indirect (such as training data) inputs.
2. Work out what data and APIs the LLM has access to.
3. [Probe](https://translate.google.com/?sl=en&tl=ar&text=Probe&op=translate) this new attack surface for vulnerabilities.